{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "from langchain.schema import BaseMemory\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "class SpacyEntityMemory(BaseMemory, BaseModel):\n",
    "    \"\"\"Memory class for storing information about entities.\"\"\"\n",
    "\n",
    "    # Define dictionary to store information about entities.\n",
    "    entities: dict = {}\n",
    "    # Define key to pass information about entities into prompt.\n",
    "    memory_key: str = \"entities\"\n",
    "\n",
    "    def clear(self):\n",
    "        self.entities = {}\n",
    "\n",
    "    @property\n",
    "    def memory_variables(self) -> List[str]:\n",
    "        \"\"\"Define the variables we are providing to the prompt.\"\"\"\n",
    "        return [self.memory_key]\n",
    "\n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"Load the memory variables, in this case the entity key.\"\"\"\n",
    "        # Get the input text and run through spaCy\n",
    "        doc = nlp(inputs[list(inputs.keys())[0]])\n",
    "        # Extract known information about entities, if they exist.\n",
    "        entities = [\n",
    "            self.entities[str(ent)] for ent in doc.ents if str(ent) in self.entities\n",
    "        ]\n",
    "        # Return combined information about entities to put into context.\n",
    "        return {self.memory_key: \"\\n\".join(entities)}\n",
    "\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"Save context from this conversation to buffer.\"\"\"\n",
    "        # Get the input text and run through spaCy\n",
    "        text = inputs[list(inputs.keys())[0]]\n",
    "        doc = nlp(text)\n",
    "        # For each entity that was mentioned, save this information to the dictionary.\n",
    "        for ent in doc.ents:\n",
    "            ent_str = str(ent)\n",
    "            if ent_str in self.entities:\n",
    "                self.entities[ent_str] += f\"\\n{text}\"\n",
    "            else:\n",
    "                self.entities[ent_str] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
    "\n",
    "Relevant entity information:\n",
    "{entities}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"entities\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, prompt=prompt, verbose=True, memory=SpacyEntityMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Harrison likes machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(\n",
    "    input=\"What do you think Harrison's favorite subject in college was?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
