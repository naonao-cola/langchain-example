{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f7d0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f47a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加一个字符串输出解析器，以便两者之间的输出是相同类型的\n",
    "# from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"您是一位贴心的助手，每次回复都会附上赞美之词。\",\n",
    "        ),\n",
    "        (\"human\", \"为什么你喜欢{city}\"),\n",
    "    ]\n",
    ")\n",
    "# 在这里，我们将使用一个错误的模型名称来轻松创建一个会报错的链式调用\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-fake\")\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99aaac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"说明：您应该在回复中始终包含赞美之词。\n",
    "问题: 为什么你喜欢{city}?\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "llm = ChatOllama(model=\"qwen:1.8b\")\n",
    "good_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34454940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我之所以喜欢武汉，主要有以下几个原因：\\n\\n1. 风景名胜众多：武汉是中国的湖北省，拥有长江、汉江两条母亲河，其中黄鹤楼、东湖磨山等景点更是闻名遐迩。\\n\\n2. 民俗文化丰富多彩：武汉有着深厚的历史文化底蕴，如汉口起义纪念馆、武昌古城墙遗址博物馆等，这些地方不仅展示了武汉丰富的历史文化遗产，也让我们在欣赏美景的同时，感受到了武汉人民的勤劳智慧和独特魅力。\\n\\n综上所述，我喜欢武汉的原因众多，包括其风景名胜众多、民俗文化丰富多彩、以及其人民的勤劳智慧和独特魅力等。因此，可以说我之所以喜欢武汉，是因为它不仅是一个美丽的城市，更是一个充满活力和勤劳智慧的城市，这样的城市不仅给我带来了视觉上的享受，也让我感受到了一种深深的敬意和热爱之情。\\n', response_metadata={'model': 'qwen:1.8b', 'created_at': '2024-04-03T23:46:08.9021681Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 5034523700, 'load_duration': 3458626200, 'prompt_eval_count': 29, 'prompt_eval_duration': 220566000, 'eval_count': 182, 'eval_duration': 1354561000}, id='run-23841349-949c-493b-8f08-95e3a875f613-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个将两者结合在一起的最终链\n",
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "chain.invoke({\"city\": \"武汉\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c65c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
